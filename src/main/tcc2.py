# -*- coding: utf-8 -*-
"""TCC2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1blTYB9UUuZc2gpigXQy3Z4IQlPHZfqjT

Projeto de Ciências de Dados seguindo a metodolodia do CRISP-DM (CRoss-Industry Standard Process for Data Mining - Processo Padrão Inter-Indústrias para Mineração de Dados) para análise dos dados de rodas de Terapia Comunitária nos convênios com Ministério da Saúde nos anos de 2008, 2009 e 2011.

O CRISP-DM é uma metodologia de mineração de dados que surgiu em 1996 como uma proposta para padronizar os processos de mineração de dados das empresas, que teve no ano 2000 sua consolidação com a apresentação da versão 1.0, evidenciando um grande progressso na padronização dos processos de modelagem e extração de conhecimentos dos dados.

A metodologia consiste de 6 fases ciclicas que vão desde o entendido do negócio até o *deployment* do modelo de dados. Para o escopo do projeto não chegaremos à fase 6, que seria a disponibilização do modelo de dados em produção, por se tratar de um projeto acadêmico e não de necessidade de negócio ou mercado.

Assim, para o projeto será utilizado a metodologia seguindo da fase 1 a 5 conforme segue:

# Fase 1: Compreensão do Negócio

Nessa fase são definidos os objetivos do projeto, incluindo os critérios de sucesso que estejam relacionados à pelo menos um objetivo e tomando cuidado para que possam ser plausíveis e realistas.

## Objetivos

Criar modelo que possa avaliar a probabiliadde de ocorrência dos temas, baseado nos dados armazenados das rodas de Terapia Comunitária referentes às formações dos convênios de 2008, 2009 e 2011 (MS/UFC/FCPC/MISMEC-CE),  para ajudar na condução das terapias.

Objetivo Específico:

*   Verificar se o perfil do público (faixa etária) que participa da terapia afeta a ocorrência de determinados temas na terapia.

## Critérios de sucesso

O modelo deverá receber como entrada o perfil (faixa etária) dos participantes da Terapia Comunitária e avaliar quais os possíves temas terão mais probabilidade de serem apresentados durante a roda de terapia.

# Fase 2: Compreensão dos Dados

## Coleta dos dados inicias

O dataset utilizado tem origem de 3 planilhas eletrônicas (xls) que consolidam os dados das fichas de registro de rodas de Terapia Comunitária dos convênios:
* **2008**: Convênio: 2397/2008 Parceria: Ministério da Saúde / FCPC – Fundação
Cearense de Pesquisa e Cultura / MISMEC-CE – Movimento Integrado de Saúde
Mental Comunitária
* **2009**: Convênio: 3363/2009 Parceria: Ministério da Saúde / FCPC – Fundação
Cearense de Pesquisa e Cultura / MISMEC-CE – Movimento Integrado de Saúde
Mental Comunitária
* **2011**: Convênio “Capacitação em Terapia Comunitária Integrativa com ênfase em
contextos de calamidades públicas” (nº 26203/11-74 - TC 101 FNS / UFC). Parceria: Ministério da Saúde / UFC - Universidade Federal do Ceará / FCPC –
Fundação Cearense de Pesquisa e Cultura / MISMEC-CE – Movimento Integrado
de Saúde Mental Comunitária.

Esse coleta inicial já traz um primeiro filtro dos registros com possível duplicidade, ou seja, registros de uma mesma terapia que podem ter sido submetidos por terapeutas de uma mesma equipe.
"""

# import das libs usadas no projeto
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Baixando o dataset do GitHub
url= "https://github.com/rafaeld3castro/tcc2/raw/main/src/main/resources/dataset.xlsx"

# Lendo o datase e transformando em um dataframe do pandas
dados = pd.read_excel(url)

#Total de registros considerados no projeto
dados['convenio'] = dados['convenio'].replace('2013_ms_calamidades', '2011_ms_calamidades')
total_registros = dados['convenio'].count()

# Gráfico de Pizza da divisão dos dadso por convênio
labels_convenio = dados['convenio'].dropna().unique()
actual_values_convenio = dados['convenio'].value_counts(dropna=True)

# cores
colors = ['#ff9999','#66b3ff','#99ff99']

fig1, ax1 = plt.subplots()

# Valores atuais ao invés de porcentagem como labels no gráfico
values=dados['convenio'].value_counts(dropna=True)
title = str(total_registros) + ' registros'
plt.title(title, fontsize = 30)
plt.pie(actual_values_convenio, colors = colors, autopct= lambda x: '{:.0f}'.format(x*values.sum()/100), startangle=90)


# draw circle (donut)
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)


# Proporção igual garante que a pizza seja desenhada como um círculo
ax1.axis('equal')

# Uma legenda separada com rótulos (desenhados na parte inferior esquerda da pizza neste caso)
plt.legend(labels_convenio, bbox_to_anchor = (0.1, .3))

plt.tight_layout()
plt.show()

"""Temos um total de **13354** registros, distribuidos da seguinte forma:

* **2008**: Convênio: 2397/2008 (4703 registros)
* **2009**: Convênio: 3363/2009 (4379 registros)
* **2011**: Convênio: 26203/11-74 - TC 101 FNS / UFC (4272 registros)

## Descrição dos Dados

* **Coluna 0 - convenio**: Convênio cuja formação dos terapeutas deu origem ao registro das rodas
* **Coluna 1 - UF**: Indica o UF no qual a terapia foi realizada
* **Coluna 2 - Data**: Inidica o data em que a terapia foi realizada
* **Coluna 3 - Horário**: Inidica o horário em que a terapia foi realizada

* **Coluna 4 - f_criancas**: Quantidade de crianças (até 12 anos) do público Feminino
* **Coluna 5 - f_adolescentes**: Quantidade de adolescentes (13 aos 20 anos) do público Feminino
* **Coluna 6 - f_adultos**: Quantidade de adultos (21 aos 59 anos) do público Feminino
* **Coluna 7 - f_idosos**: Quantidade de idosos (60 anos mais) do público Feminino
* **Coluna 8 - m_criancas**: Quantidade de crianças (até 12 anos) do público Masculino
* **Coluna 9 - m_adolescentes**: Quantidade de adolescentes (13 aos 20 anos) do público Masculino
* **Coluna 10 - m_adultos**: Quantidade de adultos (21 aos 59 anos) do público Masculino
* **Coluna 11 - m_idosos**: Quantidade de idosos (60 anos mais) do público Masculino

* **Coluna 12 - Estresse**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna 13 - Conflitos Familiares**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  14 - Violência**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  15 - Conflitos**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  16 - Problemas Escolares**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  17 - Drogas**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  18 - Alcoolismo**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  19 - Tabaco**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  20 - Depressão**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna 21 - Trabalho**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  22 - Abandono, Discriminação, Rejeição**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  23 - Problemas Mentais e Neurológicos**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  24 - Prostituição**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  25 - Outro**: 0 ou 1 pra indicar se o tema foi proposto ou não
* **Coluna  26 - Qual**: Se foi proposto outro tema, quais foram. Campo em texto aberto
* **Coluna 27 - Tema Escolhido**: Qual o tema foi escolhido na terapia

* **Coluna 28 - Fortalecimento / empoderamento pessoa**: 0 ou 1 pra indicar se a estratégia foi apresentada ou não
* **Coluna 29 - Buscar ajuda religiosa ou espiritual**: 0 ou 1 pra indicar se a estratégia foi apresentada ou não
* **Coluna 30 - Cuidar e se relacionar melhor com a família**: 0 ou 1 pra indicar se a estratégia foi apresentada ou não
* **Coluna 31 - Buscar ajuda profissional e ações de cidadania**: 0 ou 1 pra indicar se a estratégia foi apresentada ou não
* **Coluna 32 - Auto-cuidado - busca de recursos da cultura**: 0 ou 1 pra indicar se a estratégia foi apresentada ou não
* **Coluna 33 - Participar de terapia comunitária**: 0 ou 1 pra indicar se a estratégia foi apresentada ou não
* **Coluna 34 - Buscar redes solidárias**: 0 ou 1 pra indicar se a estratégia foi apresentada ou não
* **Coluna 35 - Outras**: 0 ou 1 pra indicar se a estratégia foi apresentada ou não
* **Coluna 36 - Qual**: Se foi apresentada outra estratégia, quais foram. Campo em texto aberto
* **Coluna 37**: Depoimentos apresentados ao final da terapia
"""

dados.info()

dados.describe()

"""## Verificação da qualidade dos dados

Estratégia 'e_fort_empod' está com valores NaN, isso vai atrapalhar no somatório. Como o valor não está presente, será considerado como 0, ou seja, não teve ocorrência da estratégia de enfrentamento no registro.
"""

dados['Fortalecimento / empoderamento pessoal'] = dados['Fortalecimento / empoderamento pessoal'].fillna(0)
dados['Fortalecimento / empoderamento pessoal'] = dados['Fortalecimento / empoderamento pessoal'].replace(r'^\s*$', 0, regex=True)

"""## Exploração os dados"""

dados.head()

"""### Público que participou das terapias"""

dados['criancas'] = dados["f_criancas"] + dados["m_criancas"]
dados['adolescentes'] = dados["f_adolescentes"] + dados["m_adolescentes"]
dados['adultos'] = dados["f_adultos"] + dados["m_adultos"]
dados['idosos'] = dados["f_idosos"] + dados["m_idosos"]

dados['total_pessoas'] = dados['adolescentes'] + dados['adultos'] + dados['idosos'] + dados['criancas']

total_criancas = dados['criancas'].sum()
total_adolescentes = dados['adolescentes'].sum()
total_adultos = dados['adultos'].sum()
total_idosos = dados['idosos'].sum()

print('Crianças: %d' % total_criancas)
print('Adolescentes: %d' % total_adolescentes)
print('Adultos: %d' % total_adultos)
print('Idosos: %d' % total_idosos)

dados['feminino'] = dados['f_adolescentes'] + dados['f_adultos'] + dados['f_idosos'] + dados['f_criancas']
dados['masculino'] = dados['m_adolescentes'] + dados['m_adultos'] + dados['m_idosos'] + dados['m_criancas']

total_feminino = dados['feminino'].sum()
total_masculino = dados['masculino'].sum()

print('Público Feminino: %d' % total_feminino)
print('Público Masculino: %d' % total_masculino)

dados.loc[:,['idosos','adolescentes','adultos','criancas','total_pessoas','feminino','masculino']].head(10)

dados.shape

sns.histplot(dados, x='adolescentes')

sns.histplot(dados, x='adultos')

sns.histplot(dados, x='criancas')

sns.histplot(dados, x='idosos')

categorias = ['feminino', 'masculino']
totais = [total_feminino, total_masculino]

# Criar o gráfico de barras
plt.bar(categorias, totais)

# Adicionar os valores acima das barras
for i, v in enumerate(totais):
    plt.text(i, v+30, str(v), ha='center')

# Configurar o gráfico
# A época não a classição estava binária, e não incluía os grupos minoritários
plt.xlabel('Sexo Biólogico')
plt.ylabel('Total')
plt.title('Total de pessoas por categoria')

# Exibir o gráfico
plt.show()

"""Existe uma diferença considerável entre a quantidade de pessoas do público feminino comparado ao público masculino. Diferença essa de pouco mais de 3 vezes de um para o outro."""

categorias = ['criancas', 'adolescentes','adultos','idosos']
totais =  [total_criancas, total_adolescentes,total_adultos,total_idosos]

# Criar o gráfico de barras
plt.bar(categorias, totais)

# Adicionar os valores acima das barras
for i, v in enumerate(totais):
    plt.text(i, v+30, str(v), ha='center')

# Configurar o gráfico
plt.xlabel('Categoria')
plt.ylabel('Total')
plt.title('Total de pessoas por categoria')

# Exibir o gráfico
plt.show()

"""Existe uma participação maior do público adulto nas terapias

###Temas propostos

Uma vez que os dados de tema proposto está 0 ou 1, para agrupar as ocorrências basta fazer o somatório de cada tema
"""

# Agrupando os totais de cada tema proposto
total_estresse = dados['Estresse'].sum()
total_conflitos_fam = dados['Conflitos Familiares'].sum()
total_violencia = dados['Violência'].sum()
total_conflitos = dados['Conflitos'].sum()
total_problemas_esc = dados['Problemas Escolares'].sum()
total_drogas = dados['Drogas '].sum()
total_alcoolismo = dados['Alcoolismo'].sum()
total_tabaco = dados['Tabaco'].sum()
total_depressao = dados['Depressão'].sum()
total_trabalho = dados['Trabalho'].sum()
total_aband_disc_rej = dados['Abandono, Discriminação, Rejeição'].sum()
total_problemas_men = dados['Problemas Mentais e Neurológicos'].sum()
total_prostituicao = dados['Prostituição'].sum()

# Criando agrupando do total de todos os temas
totais_temas = [
    total_estresse, total_conflitos_fam, total_violencia, total_conflitos,
    total_problemas_esc, total_drogas, total_alcoolismo, total_tabaco,
    total_depressao, total_trabalho, total_aband_disc_rej,
    total_problemas_men, total_prostituicao
]

# Criando rótulo para cada tema
labels_temas = [
    'Estresse', 'Conflitos Familiares', 'Violência', 'Conflitos',
    'Problemas Escolares', 'Drogas', 'Alcoolismo', 'Tabaco',
    'Depressão', 'Trabalho', 'Abandono, Discriminação, Rejeição',
    'Problemas Mentais e Neurológicos', 'Prostituição'
]

plt.rcdefaults()
fig, ax = plt.subplots()

# Distribuição por tema proposto
y_pos = np.arange(len(labels_temas))
error = np.random.rand(len(labels_temas))

barra_temas = ax.barh(y_pos, totais_temas, xerr=error, align='center')
ax.bar_label(barra_temas, padding=5, color='black')

ax.set_yticks(y_pos, labels=labels_temas)
ax.invert_yaxis()  # labels read top-to-bottom
ax.set_xlabel('Temas Propostos')
ax.set_title('Total por temas propostos')
ax.set_xlim(0, 9000)

# Exibir o gráfico
plt.show()

"""###Estratégias de enfrentamento

Uma vez que os dados das estratégias de enfrentamento está 0 ou 1, para agrupar as ocorrências basta fazer o somatório de cada estratégia
"""

# Agrupando os totais de cada estretégia proposta
total_fort_empod = dados['Fortalecimento / empoderamento pessoal'].sum()
total_ajuda_rel_esp = dados['Buscar ajuda religiosa ou espiritual '].sum()
total_cuid_rel_fam = dados['Cuidar e se relacionar melhor com a família '].sum()
total_busca_ajuda_pro = dados['Buscar ajuda profissional e ações de cidadania (Serviços Públicos) '].sum()
total_auto_cuidado = dados['Auto-cuidado - busca de recursos da cultura '].sum()
total_participar_tc = dados['Participar de terapia comunitária '].sum()
total_busca_redes_solid = dados['Buscar redes solidárias'].sum()

# Criando agrupamento do total de todas as estratégias propostas
totais_estrategias = [
    total_fort_empod,
    total_ajuda_rel_esp,
    total_cuid_rel_fam,
    total_busca_ajuda_pro,
    total_auto_cuidado,
    total_participar_tc,
    total_busca_redes_solid
]

# Criando rótulo para cada estratégias propostas
labels_estrategias = [
    'Fortalecimento / empoderamento pessoal',
    'Buscar ajuda religiosa ou espiritual',
    'Cuidar e se relacionar melhor com a família',
    'Buscar ajuda profissional e ações de cidadania',
    'Auto-cuidado - busca de recursos da cultura',
    'Participar de terapia comunitária',
    'Buscar redes solidárias'
]

plt.rcdefaults()
fig, ax = plt.subplots()

# Distribuição por estratégia proposta
y_pos = np.arange(len(labels_estrategias))
error = np.random.rand(len(labels_estrategias))

barra_estrategias = ax.barh(y_pos, totais_estrategias, xerr=error, align='center')
ax.bar_label(barra_estrategias, padding=5, color='black')

ax.set_yticks(y_pos, labels=labels_estrategias)
ax.invert_yaxis()  # labels read top-to-bottom
ax.set_xlabel('Estratégias de Enfretamento')
ax.set_title('Total por estratégia proposta')
ax.set_xlim(0, 10000)

# Exibir o gráfico
plt.show()

"""# Fase 3: Preparação dos Dados

## Seleção dos dados

O nome dos rótulos originais estão sendo simplificados para facilitar a visualização do conjunto de dados, bem como simplicar a seleção dos atribuitos, uma vez que os rótulos originais apresentam descrição que já foi aprensentada na fase anterior, não tendo a necessidade de mantê-los como estão, apresentando até caracteres desnessários. Assim a simplificação visa padronizar os rótulos para um tamanho mais uniforme. Segue abaixo a legenda para cada rótulo reescrito do conjunto de dados:

**Temas propostos (dado booleano - 0 ou 1):**

*   `t_estresse` = Estresse
*   `t_conflitos_fam` = Conflitos Familiares
*   `t_violencia` = Violência
*   `t_conflitos` = Conflitos
*   `t_problemas_esc` = Problemas Escolares
*   `t_drogas` = Drogas
*   `t_alcoolismo` = Alcoolismo
*   `t_tabaco` = Tabaco
*   `t_depressao` = Depressão
*   `t_trabalho` = Trabalho
*   `t_aband_disc_rej` = Abandono, Discriminação, Rejeição
*   `t_problemas_men` = Problemas Mentais e Neurológicos
*   `t_prostituicao` = Prostituição

**Estratégias de enfrentamento (dado booleano - 0 ou 1):**

*   `e_fort_empod` = Fortalecimento / empoderamento pessoal
*   `e_ajuda_rel_esp` = Buscar ajuda religiosa ou espiritual
*   `e_cuid_rel_fam` = Cuidar e se relacionar melhor com a família
*   `e_busca_ajuda_pro` = Buscar ajuda profissional e ações de cidadania (Serviços Públicos)
*   `e_auto_cuidado` = Auto-cuidado - busca de recursos da cultura
*   `e_participar_tc` = Participar de terapia comunitária
*   `e_busca_redes_solid` = Buscar redes solidárias
"""

dados = dados.rename(columns={
    "convenio": "convenio",
    "UF": "uf",
    "Data": "data",
    "Horário": "hora",
    "Estresse": "t_estresse",
    "Conflitos Familiares": "t_conflitos_fam",
    "Violência": "t_violencia",
    "Conflitos": "t_conflitos",
    "Problemas Escolares": "t_problemas_esc",
    "Drogas ": "t_drogas",
    "Alcoolismo": "t_alcoolismo",
    "Tabaco": "t_tabaco",
    "Depressão": "t_depressao",
    "Trabalho": "t_trabalho",
    "Abandono, Discriminação, Rejeição": "t_aband_disc_rej",
    "Problemas Mentais e Neurológicos": "t_problemas_men",
    "Prostituição": "t_prostituicao",
    "Outro:": "t_outro",
    "Qual:": "t_outro_qual",
    "Tema Escolhido:": "t_escolhido",
    "Fortalecimento / empoderamento pessoal": "e_fort_empod",
    "Buscar ajuda religiosa ou espiritual ": "e_ajuda_rel_esp",
    "Cuidar e se relacionar melhor com a família ": "e_cuid_rel_fam",
    "Buscar ajuda profissional e ações de cidadania (Serviços Públicos) ": "e_busca_ajuda_pro",
    "Auto-cuidado - busca de recursos da cultura ": "e_auto_cuidado",
    "Participar de terapia comunitária ": "e_participar_tc",
    "Buscar redes solidárias": "e_busca_redes_solid",
    "Outras ": "e_outras",
    "Qual:.1": "e_outras_qual",
    "Unnamed: 37": "depoimentos"
})

"""Após a padronização dos rótulos, para otimizarmos o processamentos dos dados na fase seguinte, podemos resumir o conjunto de dados mantendo somente os atributos necessários para o treinamento e teste do modelo. Assim os atributos que permanecerão no dataset final serão os dados relacionados ao público, temas propostos e estratégias de enfrentamentaento sugeridos."""

##Remover atributos do Dataframe
dados_final = dados.copy()
colunas_para_remover = [
    'uf', 'data', 'hora',
    't_outro', 't_outro_qual', 't_escolhido',
    'e_outras', 'e_outras_qual', 'depoimentos',
    ##'criancas', 'adolescentes', 'adultos', 'idosos', 'total_pessoas',
    'feminino', 'masculino'
]
dados_final.drop(columns=colunas_para_remover, inplace=True, axis=1)

"""##Limpeza dos dados

Na fase de Compreensão dos dados verificamos a qualidade dos dados e identificamos que havia um registro da estratégia de enfrentamento "*Fortalecimento / empoderamento pessoal*" que estava com valor faltante, e para poder realizar o somatório para visualização dos tatais fizemos um preenchimento com o valor 0. Assim para os valores faltantes para o atributo será mantida a estratégia de preencher o valor faltante com 0, indicando que a estratégias não foi sugerida na terapia que o registro representa.
"""

dados_final['e_fort_empod'] = dados_final['e_fort_empod'].fillna(0)
dados_final['e_fort_empod'] = dados_final['e_fort_empod'].replace(r'^\s*$', 0, regex=True)

"""Identifiquei que alguns registros estavam com o público zerado, o que pode impactar no treinamento do modelo. Assim esses registros serão removidos do dataset final para não prejudicar a criação do modelo."""

# Registros em que não teve público
publico_zerado = dados_final['total_pessoas'] == 0
total_registros_filtrados = publico_zerado.sum()

print("Total de registros com público zerado:", total_registros_filtrados)

# Removendo os registros em que não teve público
dados_final = dados_final.drop(dados_final[publico_zerado].index)

"""##Dataset Final"""

dados_final.info()

"""# Fase 4: Modelagem

### Atributos de Entrada: Publico da terapia
"""

publico_terapia = dados_final.loc[:, [
    "criancas", "adolescentes", "adultos", "idosos"
]]

"""### Atributos de Saída: Temas Propostos"""

# Crie um dicionário que associa os rótulos aos totais
temas_dicionario = dict(zip(labels_temas, totais_temas))

# Ordene os dados pelo valor em ordem decrescente
temas_ordenados = dict(sorted(temas_dicionario.items(), key=lambda item: item[1], reverse=True))

top_6_temas = list(temas_ordenados.keys())[:13]
top_6_temas_total = list(temas_ordenados.values())[:13]

visualizacao_frequencia_temas = pd.DataFrame(columns=['Tema', 'Total', 'Frequencia'])

total_registros_final = dados_final['convenio'].count()
for tema, total in zip(top_6_temas, top_6_temas_total):
    #print(f"{tema}, Total: {total}")
    #print("{} => Total: {} ({:.2%})".format(tema, total, (total / total_registros_final)))
    nova_visualizacao = pd.DataFrame([[tema, total, "{:.2%}".format(total / total_registros_final)]], columns=['Tema', 'Total', 'Frequencia'])
    visualizacao_frequencia_temas = pd.concat([visualizacao_frequencia_temas, nova_visualizacao], ignore_index=True)
    visualizacao_frequencia_temas.reset_index()

visualizacao_frequencia_temas.style.set_table_attributes("style='display:inline'").set_caption("Frequência dos temas nos registros").hide_index()

tema_target = dados_final.loc[:, [
    "t_estresse", "t_conflitos_fam", "t_trabalho", "t_depressao", "t_aband_disc_rej", "t_alcoolismo",
    "t_violencia", "t_conflitos", "t_problemas_esc", "t_drogas", "t_tabaco", "t_problemas_men", "t_prostituicao"
]]

# Crie um dicionário que associa os rótulos aos totais
estrategias_dicionario = dict(zip(labels_estrategias, totais_estrategias))

# Ordene os dados pelo valor em ordem decrescente
estrategias_ordenados = dict(sorted(estrategias_dicionario.items(), key=lambda item: item[1], reverse=True))

top_estrategias = list(estrategias_ordenados.keys())
top_estrategias_total = list(estrategias_ordenados.values())

for estrategia, total in zip(top_estrategias, top_estrategias_total):
    print(f"{estrategia}, Total: {total}")

estrategia_target = dados_final.loc[:, [
    "e_fort_empod", "e_ajuda_rel_esp", "e_cuid_rel_fam", "e_busca_ajuda_pro",
    "e_auto_cuidado", "e_participar_tc","e_busca_redes_solid"
]]

"""## Escolha dos classificadores

Aplicando o método de Validação Cruzada, usando K-Fold como validador, onde os dados de treinamento e teste serão escolhidos de acordo com a iteração do método, podemos ter uma pontuação baseada em diferentes configurações dos dados, onde os resultados das métricas adquiridas em cada confirguração será o score utilizado para escolher o modelo melhor rankeado.

### Estruturas de dados
"""

from sklearn.model_selection import KFold, cross_val_score, cross_validate
from sklearn.metrics import make_scorer, accuracy_score, precision_score, f1_score, roc_auc_score, cohen_kappa_score

import pandas as pd
import matplotlib.pyplot as plt

from IPython.display import display, HTML

from sklearn.exceptions import UndefinedMetricWarning

def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn

class Modelo:
  def __init__(self, nome, classificador):
    self.nome = nome
    self.classificador = classificador
    self.temas = []
    self.pontuacao = 0
    #self.colunas = ['Target', 'Accuracy', 'Precision', 'F1', 'Kappa', 'ROC AUC']
    self.colunas = ['Target', 'Accuracy', 'Precision', 'ROC AUC']
    self.visualizacao = pd.DataFrame(columns=self.colunas)

  def adicionar_score(self, target_nome, score):
    tema = Target(target_nome, score)
    self.temas.append(tema)

    nova_visualizacao = pd.DataFrame(
        [[tema.nome,
          "{:.2%} (std: {:.2f})".format(tema.accuracy, tema.accuracy_std),
          "{:.2%} (std: {:.2f})".format(tema.precision, tema.precision_std),
          #"{:.2%} (std: {:.2f})".format(tema.f1, tema.f1_std),
          #"{:.12f} (std: {:.2f})".format(tema.kappa, tema.kappa_std),
          "{:.12f} (std: {:.2f})".format(tema.roc, tema.roc_std)
        ]],
        columns=self.colunas
    )
    self.visualizacao = pd.concat([self.visualizacao, nova_visualizacao], ignore_index=True)
    self.visualizacao.reset_index()

  def mostrar_scores(self):
    display(self.visualizacao.style.set_table_attributes("style='display:inline'").set_caption(self.nome).hide_index())

  def pontuar(self):
    self.pontuacao = self.pontuacao + 1

  def resetar_pontuacao(self):
    self.pontuacao = 0


class Target:
  def __init__(self, nome, score):
    sorted(score.keys())

    self.nome = nome
    self.score = score
    self.accuracy = np.nanmean(score['test_accuracy'], axis=0)
    self.precision = np.nanmean(score['test_precision'], axis=0)
    self.f1 = np.nanmean(score['test_f1'], axis=0)
    self.kappa = np.nanmean(score['test_kappa'], axis=0)
    self.roc = np.nanmean(score['test_roc'], axis=0)

    self.accuracy_std = np.nanstd(score['test_accuracy'], axis=0)
    self.precision_std = np.nanstd(score['test_precision'], axis=0)
    self.f1_std = np.nanstd(score['test_f1'], axis=0)
    self.kappa_std = np.nanstd(score['test_kappa'], axis=0)
    self.roc_std = np.nanstd(score['test_roc'], axis=0)


class MetricaScore:

  def __init__(self, dados, clf, nome_clf, verbose=False):
    self.dados = dados
    self.kfold = KFold(n_splits=5, shuffle=False)
    self.clf = clf
    self.nome_clf = nome_clf
    self.modelos = []
    self.verbose = verbose

    self.temas = self.dados.loc[:, [
        "t_estresse", "t_conflitos_fam", "t_trabalho", "t_depressao", "t_aband_disc_rej", "t_alcoolismo",
        "t_violencia", "t_conflitos", "t_problemas_esc", "t_drogas", "t_tabaco", "t_problemas_men", "t_prostituicao"
    ]]

    self.temas_map = {
        'Estresse': 't_estresse',
        'Conflitos Familiares': 't_conflitos_fam',
        'Trabalho': 't_trabalho',
        'Depressão': 't_depressao',
        'Abandono, Discriminação, Rejeição': 't_aband_disc_rej',
        'Alcoolismo': 't_alcoolismo',
        'Violência': 't_violencia',
        'Conflitos': 't_conflitos',
        'Drogas': 't_drogas',
        'Tabaco': 't_tabaco',
        'Problemas Escolares': 't_problemas_esc',
        'Problemas Mentais e Neurológicos': 't_problemas_men',
        'Prostituição': 't_prostituicao'
    }

    self.average = 'weighted'
    self.scoring = {
        'accuracy': make_scorer(accuracy_score, normalize=True),
        'precision': make_scorer(precision_score, average=self.average),
        'f1': make_scorer(f1_score, average=self.average),
        'kappa': make_scorer(cohen_kappa_score),
        'roc': make_scorer(roc_auc_score, average=self.average, multi_class='ovr')
    }

  def __calcular_scores__(self, atributos):
    modelo = Modelo(self.nome_clf, self.clf)
    for tema_nome, tema_coluna in self.temas_map.items():
      x = atributos
      y = self.temas[tema_coluna]
      modelo.adicionar_score(tema_nome, cross_validate(self.clf, x, y, cv=self.kfold, scoring=self.scoring, return_estimator=True))

    self.modelos.append(modelo)

  def calcular_scores(self):
    self.__calcular_scores__(self.dados.loc[:, ["criancas", "adolescentes", "adultos", "idosos"]])

  def mostrar_scores(self):
    for modelo in self.modelos:
      modelo.mostrar_scores()

  def modelo(self):
    return self.modelos[0]

def comparar_metricas(metrica_scores, index, resumir=False):

  tema = metrica_scores[0].modelo().temas[index].nome

  if resumir:
    metrics = ("Accuracy", "Precision", "ROC AUC")
  else:
    metrics = ("Accuracy", "Precision", "F1", "Kappa", "ROC AUC")

  scores = {}

  for score in metrica_scores:
    modelo = score.modelo()
    target = modelo.temas[index]
    accuracy = target.accuracy
    precision = target.precision
    f1 = target.f1
    kappa = target.kappa
    roc = target.roc
    if resumir:
      scores[modelo.nome] = (accuracy, precision, roc)
    else:
      scores[modelo.nome] = (accuracy, precision, f1, kappa, roc)

  x = np.arange(len(metrics))  # the label locations
  width = 0.30  # the width of the bars
  multiplier = 0

  fig, ax = plt.subplots(figsize=(10, 5), layout='constrained')
  fig.canvas.manager.set_window_title('Eldorado K-8 Fitness Chart')

  plt.rcdefaults()
  sns.set_theme()
  sns.set_context("paper")

  for atributo, valores in scores.items():
      offset = width * multiplier
      rects = ax.bar(x + offset, valores, width, label=atributo)

      dentro_barra = ["{:.3f}".format(p) if p > 0.4 else '' for p in valores]
      acima_barra = ["{:.3f}".format(p) if p <= 0.4 else '' for p in valores]

      ax.bar_label(rects, dentro_barra, padding=-15, color='white', fontweight='bold')
      ax.bar_label(rects, acima_barra, padding=5, color='black', fontweight='bold')

      multiplier += 1

  # Add some text for labels, title and custom x-axis tick labels, etc.
  #ax.set_ylabel('Length (mm)')
  ax.set_title("Tema: {}".format(tema))
  ax.set_xticks(x + width, metrics)

  #ax.legend(loc='upper left', ncols=3)

  # Put a legend below current axis
  ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=5)

  ax.set_ylim(-0.1, 1)

  plt.show()

"""### Cross Validation para K-Neighbors"""

from sklearn.neighbors import KNeighborsClassifier

#knn = MetricaScore(dados_final, KNeighborsClassifier(n_neighbors=5), "K-Neighbors Classifier")
#knn.calcular_scores()

"""### Cross Validation para Multi-layer Perceptron"""

from sklearn.neural_network import MLPClassifier

#mpl = MetricaScore(dados_final, MLPClassifier(hidden_layer_sizes=(15,), random_state=1, verbose=False), 'Multi-layer Perceptron Classifier')
#mpl.calcular_scores()

"""### Cross Validation - Ensemble Classifiers"""

# Gradient-boosted trees
from sklearn.ensemble import GradientBoostingClassifier

gradient_boosting = MetricaScore(dados_final, GradientBoostingClassifier(n_estimators=10, learning_rate=1.0), 'Gradient-boosted trees Classifier')
gradient_boosting.calcular_scores()

# Random forest
from sklearn.ensemble import RandomForestClassifier

random_forests = MetricaScore(dados_final, RandomForestClassifier(n_estimators=10), 'Random Forest Classifier')
random_forests.calcular_scores()

# AdaBoost
from sklearn.ensemble import AdaBoostClassifier

ada_boost = MetricaScore(dados_final, AdaBoostClassifier(n_estimators=10, learning_rate=1.0), 'Ada Boost Classifier')
ada_boost.calcular_scores()

"""##Visualização dos Resultados

### Tabulados
"""

gradient_boosting.mostrar_scores()

random_forests.mostrar_scores()

ada_boost.mostrar_scores()

"""### Gráficos comparativos por tema"""

metricas = (gradient_boosting, random_forests, ada_boost)
for index in range(13):
  comparar_metricas(metricas, index)

"""### Gráficos comparativos por tema (resumo)"""

metricas = (gradient_boosting, random_forests, ada_boost)
for index in range(13):
  comparar_metricas(metricas, index, resumir=True)

"""## Modelo final"""

def calcular_pontuacao(metrica_scores):

  pontuacao_map = {}
  modelo_final = None

  for score in metrica_scores:
    modelo = score.modelo()
    modelo.resetar_pontuacao()
    pontuacao_map[modelo.nome] = modelo

  for i in range(13):
    max_accuracy = 0;
    max_precision = 0;
    max_roc = 0;

    for nome_modelo, modelo in pontuacao_map.items():
      if modelo.temas[i].accuracy > max_accuracy:
        max_accuracy = modelo.temas[i].accuracy

      if modelo.temas[i].precision > max_precision:
        max_precision = modelo.temas[i].precision

      if modelo.temas[i].roc > max_roc:
        max_roc = modelo.temas[i].roc

    for nome_modelo, modelo in pontuacao_map.items():
      if modelo.temas[i].accuracy == max_accuracy:
        modelo.pontuar()

      if modelo.temas[i].precision == max_precision:
        modelo.pontuar()

      if modelo.temas[i].roc == max_roc:
        modelo.pontuar()

  maior_pontuacao_geral = 0

  for nome_modelo, modelo in pontuacao_map.items():

    if modelo.pontuacao > maior_pontuacao_geral:
      maior_pontuacao_geral = modelo.pontuacao

    print(f"{nome_modelo}: {modelo.pontuacao} pontos")

  for nome_modelo, modelo in pontuacao_map.items():

    if modelo.pontuacao == maior_pontuacao_geral:
      modelo_final = modelo

  return modelo_final

metricas = (gradient_boosting, random_forests, ada_boost)

modelo_final = calcular_pontuacao(metricas)

print(f"\nModelo {modelo_final.nome} teve a maior pontuação ({modelo_final.pontuacao} pontos)")

from sklearn.model_selection import train_test_split
import copy

class ModeloTemaTerapia:

  def __init__(self, modelo_final, dados_final):
    self.modelo = modelo_final
    self.dados = dados_final
    self.publico = self.dados.loc[:, ["criancas", "adolescentes", "adultos", "idosos"]]
    self.temas = self.dados.loc[:, [
        "t_estresse", "t_conflitos_fam", "t_trabalho", "t_depressao", "t_aband_disc_rej", "t_alcoolismo",
        "t_violencia", "t_conflitos", "t_problemas_esc", "t_drogas", "t_tabaco", "t_problemas_men", "t_prostituicao"
    ]]

    self.temas_map = {
        'Estresse': 't_estresse',
        'Conflitos Familiares': 't_conflitos_fam',
        'Trabalho': 't_trabalho',
        'Depressão': 't_depressao',
        'Abandono, Discriminação, Rejeição': 't_aband_disc_rej',
        'Alcoolismo': 't_alcoolismo',
        'Violência': 't_violencia',
        'Conflitos': 't_conflitos',
        'Drogas': 't_drogas',
        'Tabaco': 't_tabaco',
        'Problemas Escolares': 't_problemas_esc',
        'Problemas Mentais e Neurológicos': 't_problemas_men',
        'Prostituição': 't_prostituicao'
    }

  def treinar(self):
    self.classificador_map = {}

    for tema_nome, tema_coluna in self.temas_map.items():
      X_train, X_test, y_train, y_test = train_test_split(self.publico, self.temas[tema_coluna], test_size=0.3, random_state=0)

      self.classificador_map[tema_coluna] = copy.deepcopy(self.modelo.classificador)
      self.classificador_map[tema_coluna].fit(self.publico, self.temas[tema_coluna])

  def prever(self, criancas, adolescentes, adultos, idosos):

    publico = [[criancas, adolescentes, adultos, idosos]]
    temas_provaveis = []

    for tema_nome, tema_coluna in self.temas_map.items():
      pode_ter_tema = self.classificador_map[tema_coluna].predict(publico)

      if (pode_ter_tema == 1):
        temas_provaveis.append(tema_nome)

    return temas_provaveis

modelo_temas_terapia = ModeloTemaTerapia(modelo_final, dados_final)

modelo_temas_terapia.treinar()

modelo_temas_terapia.prever(0, 30, 100, 50)

"""# Fase 5: Avaliação"""